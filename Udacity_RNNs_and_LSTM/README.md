# Implementing RNNs and LSTM cells in PyTorch
These tutorials will walk you through implementing RNNs and LSTM cells in PyTorch
to predict the next character in a sequence of characters.
The notebooks are based on the exercises at the Udacity Deep Learning nanodegree,
if you would like to check the instructors videos along with the notebooks then feel
free to check this Udacity free course [Link](https://www.udacity.com/course/deep-learning-pytorch--ud188)

I have added comments to the code blocks and markdown cells which explain each
step in the notebooks and they cover:
- Applying preprocessing steps to the data.
- Building deep learning RNNs and LSTM cells models using the **`nn module`**.
- Evaluating the model performance during and after training.
- Saving **`PyTorch`** models locally and reloading them.
- Early stopping the training process.
- Comparing between **`Vanilla FeedForward networks`**, **`CNNs`** and **`RNNs`**. 

**Note:** I am using **`Plotly`** to generate interactive graphs for some of the notebooks
which are not rendered over **`GitHub`**. So, feel free to download the HTML file which
has the code in the notebook with the graphs rendered.
